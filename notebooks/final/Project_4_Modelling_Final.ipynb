{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff6d3f1",
   "metadata": {
    "id": "eff6d3f1"
   },
   "source": [
    "# Executive Summary\n",
    "\n",
    "The West Nile Virus (WNV), which first originated in the West Nile area (Uganda) of Africa in 1937, recently made its way to the United States. The major vector for WNV are the mosquito species *Culex Pipiens* and *Culex Restuans*. The pathogen is further amplified by birds when they get bitten by an infected mosquito. A large majority (about 80%) of people infected with WNV are asymptomatic. In general, the illness is not life threatening with those who exhibit symptoms experiencing fevers and aches and then fatigue which may last for several weeks. However those aged 60 and above are at an increased risk of developing complications in the central nervous system, which can lead to permanent damage or even death.\n",
    "\n",
    "The windy city, Chicago, is ranked as one of the worst cities in USA for mosquito infestation. As such, the risk of transmission and propagation of WNV is a matter of serious concern. Each year, Chicago's Department of Public Health deploys workers to set up mosquito traps throughout the city to collect mosquitos to test for the presence of WNV. \n",
    "\n",
    "A new data science team was formed within the Disease And Treatment Agency, division of Societal Cures In Epidemiology and New Creative Engineering (DATA-SCIENCE) to utilize the collected data, along with data from the 2 weather stations in Chicago, to predict when WNV outbreaks are likely to occur each year. A predictive model was developed using Adaptive Boost Classifier and optimized for sensitivity.\n",
    "\n",
    "The project is divided into two separate notebooks:\n",
    "- Data Cleaning and EDA\n",
    "- Modelling and Evaluation\n",
    "\n",
    "This notebook is for **Modelling and Evaluation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f3d34",
   "metadata": {
    "id": "910f3d34"
   },
   "source": [
    "# Contents\n",
    "- [Problem Statement](#problem)\n",
    "- [Pre-processing](#preprocess)\n",
    "- [Gridsearch Cross Validation](#gs)\n",
    "- [Model Evaluation](#eval)\n",
    "    * [Model 1: Logistic Regression](#lr)\n",
    "    * [Model 2: Random Forest Classifier](#rf)\n",
    "    * [Model 3: Adaptive Boosting Classifier](#ada)\n",
    "    * [Model 4: Gradient Boosting Classifier](#gb)\n",
    "    * [Model 5: Neural Network - Multi Layer Perceptron Classifier](#nn)\n",
    "- [Kaggle Evaluation](#kaggle)\n",
    "- [Conclusions and Recommendations](#conclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c952f",
   "metadata": {
    "id": "4f6c952f"
   },
   "source": [
    "<a id='problem'></a>\n",
    "# Problem Statement\n",
    "\n",
    "With the recent rise in cases of WNV in Chicago, DATA-SCIENCE has initiated a project to construct a machine learning model to predict the occurence of WNV in the City. Current pesticide application practices do not appear to be effective in curbing the spread of the virus. This project aims to use the findings from machine learning to devise a more effective strategy to annual pesticide application in Chicago.\n",
    "\n",
    "- Accurately predict the occurance of WNV\n",
    "- Optimize model for sensitivity\n",
    "- Recommend spraying strategy\n",
    "\n",
    "### Stakeholders\n",
    "\n",
    "- Disease and Treatment Agency, division of Societal Cures in Epidemiology and New Creative Engineering (DATA-SCIENCE)\n",
    "- Department of Public Health Chicago\n",
    "- Chicago Citizens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a1dd7",
   "metadata": {
    "id": "4c0a1dd7"
   },
   "source": [
    "## Modelling Process Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3446d96",
   "metadata": {
    "id": "d3446d96"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine LearningI\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import  RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (confusion_matrix , accuracy_score, roc_auc_score, plot_roc_curve, \n",
    "                             precision_score, recall_score, make_scorer, f1_score, classification_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Options\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dad8c7",
   "metadata": {
    "id": "b8dad8c7"
   },
   "source": [
    "#### Import model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a79dc4",
   "metadata": {
    "id": "f2a79dc4"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../datasets/train_df.csv')\n",
    "test_df = pd.read_csv('../../datasets/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3aed0c",
   "metadata": {
    "id": "0d3aed0c"
   },
   "outputs": [],
   "source": [
    "#Drop non predictive features\n",
    "train_df.drop(columns = ['latitude','longitude','nummosquitos','trap','date'], inplace = True)\n",
    "test_df.drop(columns = ['latitude','longitude','trap','date'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ccaa9",
   "metadata": {
    "id": "ce8ccaa9"
   },
   "source": [
    "<a id='preprocess'></a>\n",
    "## Pre-processing\n",
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2cfde1",
   "metadata": {
    "id": "4c2cfde1"
   },
   "outputs": [],
   "source": [
    "target = 'wnvpresent'\n",
    "\n",
    "X = train_df.drop('wnvpresent', axis = 1)\n",
    "y = train_df[target]\n",
    "X_test = test_df[X.columns]\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout  = train_test_split(X, y, random_state = 25, train_size = 0.75, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda4d6e5",
   "metadata": {
    "id": "eda4d6e5",
    "outputId": "c90b551c-70fc-4f8a-d163-cf233d46f940"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['culex_pipiens', 'culex_pipiens/restuans', 'culex_restuans', 'tavg',\n",
       "       'depart', 'dewpoint', 'cool', 'weathertype_vc', 'weathertype_dz',\n",
       "       'weathertype_ra', 'weathertype_hz', 'weathertype_br', 'weathertype_fg',\n",
       "       'weathertype_ts', 'daylighthours', 'relative_humidity',\n",
       "       'preciptotal_roll1_lag10', 'stnpressure_roll7_lag28',\n",
       "       'sealevel_roll7_lag28', 'resultspeed_roll7_lag28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51f2e19",
   "metadata": {
    "id": "c51f2e19"
   },
   "outputs": [],
   "source": [
    "fix_cols = [x for x in X_train.columns if x.startswith('culex') or x.startswith('weathertype') or x.startswith('wnvpresent')]\n",
    "cols = [x for x in X_train.columns if x not in fix_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc300bac",
   "metadata": {
    "id": "fc300bac",
    "outputId": "0f77713e-7286-4c9d-ce5b-a00decfd638b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tavg',\n",
       " 'depart',\n",
       " 'dewpoint',\n",
       " 'cool',\n",
       " 'daylighthours',\n",
       " 'relative_humidity',\n",
       " 'preciptotal_roll1_lag10',\n",
       " 'stnpressure_roll7_lag28',\n",
       " 'sealevel_roll7_lag28',\n",
       " 'resultspeed_roll7_lag28']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b08c86",
   "metadata": {
    "id": "34b08c86"
   },
   "source": [
    "### Data Transfomation\n",
    "- Standard Scaler\n",
    "    * Performed only on numerical features, excluding non-binary features\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "    * Uses synthetic data generation to increase the number of samples in the data set to make classes more balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e76cc41e",
   "metadata": {
    "id": "e76cc41e",
    "outputId": "2c93d23c-2219-449e-abf2-bf21b44d16d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Standard Scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "for i in cols:\n",
    "    X_train.loc[:,i] = ss.fit_transform(X_train[[i]])\n",
    "    X_holdout.loc[:,i] = ss.transform(X_holdout[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2a37e7",
   "metadata": {
    "id": "8e2a37e7"
   },
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "sm = SMOTE(random_state = 25)\n",
    "\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "X_holdout_sm, y_holdout_sm = sm.fit_resample(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6556d9",
   "metadata": {
    "id": "8e6556d9"
   },
   "source": [
    "<a id='gs'></a>\n",
    "## Gridsearch Cross Validation\n",
    "\n",
    "In this section, we set up the gridsearch cross validation for our desired models and hyperparameters. We will comment on the choice of hyperparameters and results of the gridsearch in a later section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1a805e",
   "metadata": {
    "id": "cf1a805e"
   },
   "outputs": [],
   "source": [
    "#Function which performs gridsearching over different pipelines\n",
    "#inputs are lists containing models and respective parameters for each pipeline\n",
    "#outputs are lists containing the cross validated score and best parameters for each pipeline\n",
    "\n",
    "def gridsearcher(models,parameters,X,y):\n",
    "    cross_val_scores = []\n",
    "    best_params = []\n",
    "    \n",
    "    for n, p in enumerate(parameters):\n",
    "        gs = GridSearchCV(models[n],\n",
    "                         param_grid = parameters[n],\n",
    "                         cv = 5,\n",
    "                         verbose = 1,\n",
    "                         n_jobs = -1,\n",
    "                         scoring = 'roc_auc'\n",
    "                         )\n",
    "        gs.fit(X,y)\n",
    "        cross_val_scores.append(gs.best_score_)\n",
    "        best_params.append(gs.best_params_)\n",
    "    return cross_val_scores, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e4ef1d",
   "metadata": {
    "id": "89e4ef1d"
   },
   "outputs": [],
   "source": [
    "#Instantiate models\n",
    "#List of models used in gridsearch\n",
    "lr = LogisticRegression(random_state = 25, max_iter = 2000)\n",
    "rf = RandomForestClassifier(random_state = 25)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),random_state=25, n_estimators= 200)\n",
    "gb = GradientBoostingClassifier(random_state= 25, n_estimators = 500)\n",
    "nn = MLPClassifier(activation = 'relu',\n",
    "                  solver = 'adam',\n",
    "                  batch_size = 'auto',\n",
    "                  max_iter = 2000,\n",
    "                  random_state = 25,\n",
    "                  verbose = 1,\n",
    "                  early_stopping = True)\n",
    "\n",
    "models_list = [lr,\n",
    "               rf,\n",
    "               ada,\n",
    "               gb,\n",
    "               nn]\n",
    "\n",
    "#Hyperparameters to gridsearch over\n",
    "params_list = [\n",
    "    #Logistic Regression\n",
    "    {'penalty': ['elasticnet'],\n",
    "     'C': [0.1 , 1 , 10],\n",
    "     'l1_ratio' : [0,0.3,0.5,0.7,1],\n",
    "     'class_weight': ['balanced',None],\n",
    "     'solver': ['saga']}, \n",
    "    #Random Forest Classifier\n",
    "    {'criterion': ['gini','entropy'], \n",
    "    'n_estimators' : [2000,2500,3000],\n",
    "     'max_depth': [None, 5, 10],\n",
    "     'max_features': ['sqrt', 'log2', None]},\n",
    "    #Ada boost\n",
    "    {'base_estimator__criterion': ['gini','entropy'], \n",
    "     'base_estimator__max_depth': [None, 5, 10, 15],\n",
    "     'base_estimator__ccp_alpha': [0,2,3],\n",
    "     'base_estimator__class_weight': ['none', 'balanced']},\n",
    "    #Gradient boost\n",
    "    {'criterion': ['friedman_mse', 'mse'],\n",
    "     'max_depth': [5, 10, 11],\n",
    "     'loss': ['deviance', 'exponential']},\n",
    "    #Neural Network\n",
    "    {'learning_rate' : ['adaptive','constant'],\n",
    "    'validation_fraction' : [0.1,0.15,0.2,0.3],\n",
    "    'hidden_layer_sizes' : [(128,),(100,),(64,)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3deac8d",
   "metadata": {
    "id": "b3deac8d",
    "outputId": "dc205c05-486b-4665-a299-eac796b6e661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.9069038  0.90685121 0.90639575 0.90694929\n",
      " 0.90626701 0.90655006 0.90635677 0.90647777        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.5               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.5        0.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5       ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Iteration 1, loss = 0.63650958\n",
      "Validation score: 0.693750\n",
      "Iteration 2, loss = 0.56216287\n",
      "Validation score: 0.743304\n",
      "Iteration 3, loss = 0.52560426\n",
      "Validation score: 0.766964\n",
      "Iteration 4, loss = 0.50115161\n",
      "Validation score: 0.768750\n",
      "Iteration 5, loss = 0.48335218\n",
      "Validation score: 0.775446\n",
      "Iteration 6, loss = 0.46908380\n",
      "Validation score: 0.780804\n",
      "Iteration 7, loss = 0.45840427\n",
      "Validation score: 0.781696\n",
      "Iteration 8, loss = 0.45053907\n",
      "Validation score: 0.782143\n",
      "Iteration 9, loss = 0.44478751\n",
      "Validation score: 0.785268\n",
      "Iteration 10, loss = 0.43988108\n",
      "Validation score: 0.790179\n",
      "Iteration 11, loss = 0.43610750\n",
      "Validation score: 0.782143\n",
      "Iteration 12, loss = 0.43189304\n",
      "Validation score: 0.789286\n",
      "Iteration 13, loss = 0.42930821\n",
      "Validation score: 0.794643\n",
      "Iteration 14, loss = 0.42643068\n",
      "Validation score: 0.795982\n",
      "Iteration 15, loss = 0.42403626\n",
      "Validation score: 0.790179\n",
      "Iteration 16, loss = 0.42292598\n",
      "Validation score: 0.797768\n",
      "Iteration 17, loss = 0.42030506\n",
      "Validation score: 0.794643\n",
      "Iteration 18, loss = 0.41829088\n",
      "Validation score: 0.804018\n",
      "Iteration 19, loss = 0.41775079\n",
      "Validation score: 0.797321\n",
      "Iteration 20, loss = 0.41672678\n",
      "Validation score: 0.798214\n",
      "Iteration 21, loss = 0.41504324\n",
      "Validation score: 0.800000\n",
      "Iteration 22, loss = 0.41308873\n",
      "Validation score: 0.800893\n",
      "Iteration 23, loss = 0.41262318\n",
      "Validation score: 0.800446\n",
      "Iteration 24, loss = 0.41200278\n",
      "Validation score: 0.804911\n",
      "Iteration 25, loss = 0.41013465\n",
      "Validation score: 0.803571\n",
      "Iteration 26, loss = 0.40877906\n",
      "Validation score: 0.800446\n",
      "Iteration 27, loss = 0.40789034\n",
      "Validation score: 0.800000\n",
      "Iteration 28, loss = 0.40743740\n",
      "Validation score: 0.798214\n",
      "Iteration 29, loss = 0.40708798\n",
      "Validation score: 0.801786\n",
      "Iteration 30, loss = 0.40562502\n",
      "Validation score: 0.798661\n",
      "Iteration 31, loss = 0.40665327\n",
      "Validation score: 0.802232\n",
      "Iteration 32, loss = 0.40423823\n",
      "Validation score: 0.798661\n",
      "Iteration 33, loss = 0.40405446\n",
      "Validation score: 0.802679\n",
      "Iteration 34, loss = 0.40318690\n",
      "Validation score: 0.802679\n",
      "Iteration 35, loss = 0.40236659\n",
      "Validation score: 0.799107\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores, best_params = gridsearcher(models = models_list,\n",
    "                                             parameters = params_list,\n",
    "                                             X = X_train_sm,\n",
    "                                             y = y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f238ab",
   "metadata": {
    "id": "50f238ab",
    "outputId": "41c70c87-de99-4cfb-91f0-d91517de1d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8189572287106,\n",
       " 0.9043329746082464,\n",
       " 0.9069492906185024,\n",
       " 0.9070379611999704,\n",
       " 0.8816777173899789]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print scores from gridsearch\n",
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3edfacf2",
   "metadata": {
    "id": "3edfacf2",
    "outputId": "8d9e62cc-7329-4212-9695-5f869e04606f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1,\n",
       "  'class_weight': 'balanced',\n",
       "  'l1_ratio': 0.3,\n",
       "  'penalty': 'elasticnet',\n",
       "  'solver': 'saga'},\n",
       " {'criterion': 'entropy',\n",
       "  'max_depth': None,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 2500},\n",
       " {'base_estimator__ccp_alpha': 0,\n",
       "  'base_estimator__class_weight': 'balanced',\n",
       "  'base_estimator__criterion': 'gini',\n",
       "  'base_estimator__max_depth': 15},\n",
       " {'criterion': 'friedman_mse', 'loss': 'exponential', 'max_depth': 10},\n",
       " {'hidden_layer_sizes': (100,),\n",
       "  'learning_rate': 'adaptive',\n",
       "  'validation_fraction': 0.15}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print best hyperparameters from gridsearch\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9372e27b",
   "metadata": {
    "id": "9372e27b",
    "outputId": "fce8faf8-57f6-468a-99ad-e5333f1d4844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, learning_rate='adaptive', max_iter=2000,\n",
       "              random_state=25, validation_fraction=0.15, verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Gridsearch Set-up\n",
    "lr = LogisticRegression(random_state = 25, max_iter = 2000)\n",
    "lr.set_params(**best_params[0])\n",
    "\n",
    "# Random Forest Gridsearch set-up\n",
    "rf = RandomForestClassifier(random_state = 25)\n",
    "rf.set_params(**best_params[1])\n",
    "\n",
    "# ADABOOST fit\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),random_state=25, n_estimators= 200)\n",
    "ada.set_params(**best_params[2])\n",
    "\n",
    "# Gradient boost Set up\n",
    "gb = GradientBoostingClassifier(random_state= 25, n_estimators = 500)\n",
    "gb.set_params(**best_params[3])\n",
    "\n",
    "#Neural Network set-up\n",
    "nn = MLPClassifier(activation = 'relu',\n",
    "                  solver = 'adam',\n",
    "                  batch_size = 'auto',\n",
    "                  max_iter = 2000,\n",
    "                  random_state = 25,\n",
    "                  verbose = 1,\n",
    "                  early_stopping = True)\n",
    "nn.set_params(**best_params[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1d62e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "2f1d62e4",
    "outputId": "fb7dc7c9-7e79-40ca-92dc-e37bef1d1cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63650958\n",
      "Validation score: 0.693750\n",
      "Iteration 2, loss = 0.56216287\n",
      "Validation score: 0.743304\n",
      "Iteration 3, loss = 0.52560426\n",
      "Validation score: 0.766964\n",
      "Iteration 4, loss = 0.50115161\n",
      "Validation score: 0.768750\n",
      "Iteration 5, loss = 0.48335218\n",
      "Validation score: 0.775446\n",
      "Iteration 6, loss = 0.46908380\n",
      "Validation score: 0.780804\n",
      "Iteration 7, loss = 0.45840427\n",
      "Validation score: 0.781696\n",
      "Iteration 8, loss = 0.45053907\n",
      "Validation score: 0.782143\n",
      "Iteration 9, loss = 0.44478751\n",
      "Validation score: 0.785268\n",
      "Iteration 10, loss = 0.43988108\n",
      "Validation score: 0.790179\n",
      "Iteration 11, loss = 0.43610750\n",
      "Validation score: 0.782143\n",
      "Iteration 12, loss = 0.43189304\n",
      "Validation score: 0.789286\n",
      "Iteration 13, loss = 0.42930821\n",
      "Validation score: 0.794643\n",
      "Iteration 14, loss = 0.42643068\n",
      "Validation score: 0.795982\n",
      "Iteration 15, loss = 0.42403626\n",
      "Validation score: 0.790179\n",
      "Iteration 16, loss = 0.42292598\n",
      "Validation score: 0.797768\n",
      "Iteration 17, loss = 0.42030506\n",
      "Validation score: 0.794643\n",
      "Iteration 18, loss = 0.41829088\n",
      "Validation score: 0.804018\n",
      "Iteration 19, loss = 0.41775079\n",
      "Validation score: 0.797321\n",
      "Iteration 20, loss = 0.41672678\n",
      "Validation score: 0.798214\n",
      "Iteration 21, loss = 0.41504324\n",
      "Validation score: 0.800000\n",
      "Iteration 22, loss = 0.41308873\n",
      "Validation score: 0.800893\n",
      "Iteration 23, loss = 0.41262318\n",
      "Validation score: 0.800446\n",
      "Iteration 24, loss = 0.41200278\n",
      "Validation score: 0.804911\n",
      "Iteration 25, loss = 0.41013465\n",
      "Validation score: 0.803571\n",
      "Iteration 26, loss = 0.40877906\n",
      "Validation score: 0.800446\n",
      "Iteration 27, loss = 0.40789034\n",
      "Validation score: 0.800000\n",
      "Iteration 28, loss = 0.40743740\n",
      "Validation score: 0.798214\n",
      "Iteration 29, loss = 0.40708798\n",
      "Validation score: 0.801786\n",
      "Iteration 30, loss = 0.40562502\n",
      "Validation score: 0.798661\n",
      "Iteration 31, loss = 0.40665327\n",
      "Validation score: 0.802232\n",
      "Iteration 32, loss = 0.40423823\n",
      "Validation score: 0.798661\n",
      "Iteration 33, loss = 0.40405446\n",
      "Validation score: 0.802679\n",
      "Iteration 34, loss = 0.40318690\n",
      "Validation score: 0.802679\n",
      "Iteration 35, loss = 0.40236659\n",
      "Validation score: 0.799107\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, learning_rate='adaptive', max_iter=2000,\n",
       "              random_state=25, validation_fraction=0.15, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_sm, y_train_sm)\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "ada.fit(X_train_sm, y_train_sm)\n",
    "gb.fit(X_train_sm,y_train_sm)\n",
    "nn.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ff14c",
   "metadata": {
    "id": "418ff14c"
   },
   "source": [
    "<a id='eval'></a>\n",
    "## Model Evaluation\n",
    "\n",
    "The 6 model combinations have been optimised by gridsearch. We will evaluate the result by creating a function that generates all the evaluation metrics. In this section, we will generate the results. We will compare and comment on the results in the next section Model Selection.\n",
    "\n",
    "As we are dealing with an unbalanced class (5% of train data is positive class) and are interested in the positive cases, we are looking for the model that provides the best Sensitivity/Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe88b6",
   "metadata": {
    "id": "7dfe88b6"
   },
   "source": [
    "<a id='lr'></a>\n",
    "### Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669f7d3",
   "metadata": {
    "id": "5669f7d3"
   },
   "source": [
    "#### Hyperparameters:\n",
    "l1 ratio -> Weights of l1 penalty term as compared to l2 penalty term\n",
    "\n",
    "C -> Inverse of regularization strength, smaller values have more regularisation, regularisation will reduce the variance of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a29f9f",
   "metadata": {
    "id": "03a29f9f"
   },
   "source": [
    "From grid searching, we get the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78abd94",
   "metadata": {
    "id": "b78abd94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'class_weight': 'balanced',\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': 0.3,\n",
       " 'max_iter': 2000,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'elasticnet',\n",
       " 'random_state': 25,\n",
       " 'solver': 'saga',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718507d4",
   "metadata": {
    "id": "718507d4"
   },
   "source": [
    "#### Interpreting Intercept and Coefficients\n",
    "The logistic regression model is a commonly used binary classifier and is used in pipelines 1 and 2. It assumes a linear relationship between features and the log-odds of class = 1.\n",
    "\n",
    "To interpret the intercept and coefficients of the model, we need to first exponentiate the values. The result is interpreted as odds. For the exponentiated intercept, it is the likelihood of predicting class 1 as opposed to class 0 when the other predictors are = 0. For coefficients, the sign represents whether the feature increases or decreases the odds of predicting class 1. The magnitude of the exponentiated coefficient represents an increase in likelihood of predicting class 1 (or class 0 for negative coefficients).\n",
    "\n",
    "The exponentiated intercept represents an odds of 1.8814 in predicting WNV +ve on average. This ties in with having more false negatives than false positives. The intercept may account for shorter documents with weak predictive features which were then misclassified .\n",
    "\n",
    "The sign of the coefficient for logistic regression tells us whether the feature predicts WNV +ve or WNV -ve.\n",
    "The coefficients themselves can be interpreted by exponentiating their values. The result represents an increase in odds of predicting WNV +ve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb2ddb",
   "metadata": {
    "id": "debb2ddb"
   },
   "source": [
    "#### Interpreting top coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b07a47f1",
   "metadata": {
    "id": "b07a47f1",
    "outputId": "9ec0eec8-2ea4-4fc7-eca7-67e9efc79018",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stnpressure_roll7_lag28</td>\n",
       "      <td>2.138130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dewpoint</td>\n",
       "      <td>1.958766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tavg</td>\n",
       "      <td>1.849957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>weathertype_fg</td>\n",
       "      <td>1.443824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cool</td>\n",
       "      <td>0.274012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resultspeed_roll7_lag28</td>\n",
       "      <td>0.240777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weathertype_ts</td>\n",
       "      <td>0.125751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>preciptotal_roll1_lag10</td>\n",
       "      <td>0.038444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weathertype_br</td>\n",
       "      <td>-0.113051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weathertype_ra</td>\n",
       "      <td>-0.371281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>-0.657410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weathertype_dz</td>\n",
       "      <td>-0.797413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>weathertype_hz</td>\n",
       "      <td>-0.866485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weathertype_vc</td>\n",
       "      <td>-1.361058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culex_pipiens</td>\n",
       "      <td>-1.637003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culex_pipiens/restuans</td>\n",
       "      <td>-1.712533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sealevel_roll7_lag28</td>\n",
       "      <td>-1.758394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>daylighthours</td>\n",
       "      <td>-2.359813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culex_restuans</td>\n",
       "      <td>-2.810066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depart</td>\n",
       "      <td>-3.224671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Coefficients\n",
       "17  stnpressure_roll7_lag28      2.138130\n",
       "5                  dewpoint      1.958766\n",
       "3                      tavg      1.849957\n",
       "12           weathertype_fg      1.443824\n",
       "6                      cool      0.274012\n",
       "19  resultspeed_roll7_lag28      0.240777\n",
       "13           weathertype_ts      0.125751\n",
       "16  preciptotal_roll1_lag10      0.038444\n",
       "11           weathertype_br     -0.113051\n",
       "9            weathertype_ra     -0.371281\n",
       "15        relative_humidity     -0.657410\n",
       "8            weathertype_dz     -0.797413\n",
       "10           weathertype_hz     -0.866485\n",
       "7            weathertype_vc     -1.361058\n",
       "0             culex_pipiens     -1.637003\n",
       "1    culex_pipiens/restuans     -1.712533\n",
       "18     sealevel_roll7_lag28     -1.758394\n",
       "14            daylighthours     -2.359813\n",
       "2            culex_restuans     -2.810066\n",
       "4                    depart     -3.224671"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a table of top coefficients\n",
    "\n",
    "lrcoef = pd.DataFrame({\"Feature\":X_train.columns.tolist(),\n",
    "             \"Coefficients\":lr.coef_[0]})\n",
    "lrcoef.sort_values('Coefficients', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eaeeed9",
   "metadata": {
    "id": "3eaeeed9",
    "outputId": "860fef0d-ec37-4e79-e7f2-6b0f4e8ebe49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.37412924])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exponentiated Intercept\n",
    "np.exp(lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2262e63",
   "metadata": {
    "id": "b2262e63"
   },
   "source": [
    "##### Notable features:\n",
    "\n",
    "stnpressure_roll7_lag28 has a high positive coefficient, this supports our hypothesis that rainy season in the past creates an environment for mosquito to breed causing a rise in WNV presence in the future.\n",
    "\n",
    "dewpoint & tavg has high positive coefficients, this is logical as mosquitoes are more active in humid and hot climates.\n",
    "\n",
    "daylighthours has a strong negative coefficient, this agrees with the hypothesis that coolex species of mosquitoes are more active at night, so a less day light hours means more active time for this species which is a known carrier of WNV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c1039d",
   "metadata": {
    "id": "c2c1039d"
   },
   "source": [
    "<a id='rf'></a>\n",
    "### Model 2: Random Forest\n",
    "\n",
    "The Random Forest Classifier is an ensemble method that uses bootsrap aggregating to repeatedly sample the training set with replacement and constructs multiple decision trees as a result. Additionally, a random subset of features is selected for each split within the decision tree algorithm to reduce the correlation between decision trees. Correlation between trees occurs when there are few features that are strong predictors of the target class as these features will be used in many of the bagged decision trees.\n",
    "\n",
    "#### Hyperparameters:\n",
    "\n",
    "max_depth -> The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. The lower the depth the less variance the model will have, it will also increase the bias.\n",
    "\n",
    "n_estimators -> The number of trees in the forest. The less trees, the lower the variance of the model.\n",
    "\n",
    "max_features -> The number of features to consider when looking for the best split. \n",
    "\n",
    "criterion -> The criterion of split, either “gini” for the Gini impurity or “entropy” for the information gain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3354d",
   "metadata": {
    "id": "f7e3354d"
   },
   "source": [
    "From grid searching, we get the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d69ed7",
   "metadata": {
    "id": "f9d69ed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 2500,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 25,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eeb20a",
   "metadata": {
    "id": "d4eeb20a"
   },
   "source": [
    "#### Feature importance\n",
    "\n",
    "In the Random Forest Classifier algorithm, feature importance (or gini importance) is the feature's average impurity decrease calculated from all decision trees in the forest. When the decision tree is figuring out which split to make at a given node, it picks the split that maximizes the drop in gini impurity from the parent node to the child node. Therefore a higher feature importance shows how strong of a predictor that feature is of either class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338a2df8",
   "metadata": {
    "id": "338a2df8"
   },
   "outputs": [],
   "source": [
    "# Get features importance in dictionary\n",
    "important_features_dict = {}\n",
    "for idx, val in enumerate(rf.feature_importances_):\n",
    "    important_features_dict[idx] = val\n",
    "\n",
    "# Sort values of feature importance    \n",
    "\n",
    "important_features_list = sorted(important_features_dict,\n",
    "                                 key=important_features_dict.get,\n",
    "                                 reverse=True)\n",
    "\n",
    "# Create list of sorted values\n",
    "imp_features = []\n",
    "importance = []\n",
    "for i in important_features_list:\n",
    "    imp_features.append(X_train.columns[i])\n",
    "    importance.append(important_features_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358fe6b6",
   "metadata": {
    "id": "358fe6b6",
    "outputId": "8ebe6538-40b2-448a-ee8b-b0a71c40170e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "\n",
    "plt.figure(figsize = (16,8))\n",
    "forest_importances = pd.Series(importance, index= imp_features)\n",
    "forest_importances.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "igglennqTtzH",
   "metadata": {
    "id": "igglennqTtzH"
   },
   "source": [
    "The plot above shows the feature importance of the Random Forest model sorted in order of importance. \n",
    "\n",
    "Looking at the top 3 features:\n",
    "\n",
    "daylighthours - supports our hypothesis that the day light hours affects mosquito activity levels, which increases the spread of WNV\n",
    "\n",
    "culex_restuans - This is the species of mosquitos that have the highest rate of having WNV based on our data. They are known carriers of the virus.\n",
    "\n",
    "resultspeed_roll7_lag28 - supports our hypothesis that past rainy season may cause mosquito outbreaks which increases the spread of WNV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc04e93",
   "metadata": {
    "id": "ffc04e93"
   },
   "source": [
    "<a id='ada'></a>\n",
    "### Model 3: Adaptive Boosting Classifier\n",
    "\n",
    "Adaptive Boosting is a boosting algorithm that combines multiple weak classifiers into a single strong classifier. It creates single split decision trees called decision stump; the decision of the trees will be weighted depending on its ability to classify the data. A benefit Adaptive Boost brings is that it allows us to capture some non-linear relationships. \n",
    "[Link](https://towardsdatascience.com/understanding-adaboost-2f94f22d5bfe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1fa46",
   "metadata": {
    "id": "3ff1fa46"
   },
   "source": [
    "#### Hyperparameters:\n",
    "\n",
    "criterion -> The criterion of split\n",
    "\n",
    "max_depth -> The maximum depth of the tree.\n",
    "\n",
    "ccp_alpha -> Impurity threshold of each split.\n",
    "\n",
    "class_weight -> Balance weights will add weights to the observations. The weights will be inversely proportion to their frequencies. This method deals penalizes the majority class, which helps for imbalanced classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2b9e8",
   "metadata": {
    "id": "47e2b9e8"
   },
   "source": [
    "From grid searching, we get the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca6ce6ac",
   "metadata": {
    "id": "ca6ce6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'base_estimator__ccp_alpha': 0,\n",
       " 'base_estimator__class_weight': 'balanced',\n",
       " 'base_estimator__criterion': 'gini',\n",
       " 'base_estimator__max_depth': 15,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_impurity_split': None,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeClassifier(ccp_alpha=0, class_weight='balanced', max_depth=15),\n",
       " 'learning_rate': 1.0,\n",
       " 'n_estimators': 200,\n",
       " 'random_state': 25}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39356230",
   "metadata": {
    "id": "39356230"
   },
   "source": [
    "<a id='gb'></a>\n",
    "### Model 4: Gradient Boosting Classifier\n",
    "\n",
    "Gradient boost is similar to Adaboost, but the weights of the decision of the trees are dependent on some loss function. \n",
    "[Link]( https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7f03d",
   "metadata": {
    "id": "e0e7f03d"
   },
   "source": [
    "#### Hyperparameters:\n",
    "\n",
    "criterion -> The criterion of split\n",
    "\n",
    "max_depth -> The maximum depth of the tree.\n",
    "\n",
    "loss -> The loss function to be optimized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf85322",
   "metadata": {
    "id": "daf85322"
   },
   "source": [
    "From grid searching, we get the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d55add",
   "metadata": {
    "id": "b1d55add"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'exponential',\n",
       " 'max_depth': 10,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': 25,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2ed202",
   "metadata": {
    "id": "ab2ed202"
   },
   "source": [
    "<a id='nn'></a>\n",
    "### Model 5: Neural Network - Multilayer Perceptron Classifier\n",
    "\n",
    "MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.\n",
    "\n",
    "It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.\n",
    "[link](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380663",
   "metadata": {
    "id": "eb380663"
   },
   "source": [
    "#### Hyperparameters:\n",
    "\n",
    "learning_rate -> Learning rate schedule for weight updates.\n",
    "\n",
    "validation_fraction -> The proportion of training data to set aside as validation set for early stopping.\n",
    "\n",
    "hidden_layer_sizes -> The amount of nodes in the hidden layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb45dd",
   "metadata": {
    "id": "7ecb45dd"
   },
   "source": [
    "From grid searching, we get the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a00257b",
   "metadata": {
    "id": "4a00257b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': True,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 2000,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 25,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.15,\n",
       " 'verbose': 1,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df119e",
   "metadata": {
    "id": "26df119e"
   },
   "source": [
    "<a id='selection'></a>\n",
    "## Model Selection\n",
    "\n",
    "In this section we will evaluate the results of the models and choose the ideal model.\n",
    "\n",
    "After selecting the ideal hyperparameters from gridsearching, we generate the evaluation metrics for the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8c80e04",
   "metadata": {
    "id": "e8c80e04"
   },
   "outputs": [],
   "source": [
    "# Function to get evaluation metrics\n",
    "def metrics(model,X_train,y_train,X_test,y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print('Train Data Evaluation Score')\n",
    "    print(f'AUCROC: {roc_auc_score(y_train,model.predict_proba(X_train)[:, 1])}')\n",
    "    print('--------------')\n",
    "    print('Test Data Evaluation Scores')\n",
    "    print(f'AUCROC: {roc_auc_score(y_test,model.predict_proba(X_test)[:, 1])}')\n",
    "    print(f'Sensitivity: {cm[1,1]/(cm[1,1]+cm[1,0])}')\n",
    "    print(f'Precision: {cm[1,1]/(cm[1,1]+cm[0,1])}')\n",
    "    print(f'F1_score: {f1_score(pred, y_test)}')\n",
    "    print('--------------')\n",
    "    print(f'Outcome values :\\n True Positive : {cm[1,1]} \\n False Negative: {cm[1,0]} \\n False Positive: {cm[0,1]} \\n True Negative : {cm[0,0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "777fb25f",
   "metadata": {
    "id": "777fb25f",
    "outputId": "6a887669-130d-4d5b-a10b-96c6215dc9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "\n",
      "Train Data Evaluation Score\n",
      "AUCROC: 0.8199724185842145\n",
      "--------------\n",
      "Test Data Evaluation Scores\n",
      "AUCROC: 0.7942192021707105\n",
      "Sensitivity: 0.7898550724637681\n",
      "Precision: 0.12124582869855395\n",
      "F1_score: 0.210221793635487\n",
      "--------------\n",
      "Outcome values :\n",
      " True Positive : 109 \n",
      " False Negative: 29 \n",
      " False Positive: 790 \n",
      " True Negative : 1699\n",
      "\n",
      "Random Forest\n",
      "\n",
      "Train Data Evaluation Score\n",
      "AUCROC: 0.9119886300886906\n",
      "--------------\n",
      "Test Data Evaluation Scores\n",
      "AUCROC: 0.8317670212704014\n",
      "Sensitivity: 0.7318840579710145\n",
      "Precision: 0.15279878971255673\n",
      "F1_score: 0.2528160200250313\n",
      "--------------\n",
      "Outcome values :\n",
      " True Positive : 101 \n",
      " False Negative: 37 \n",
      " False Positive: 560 \n",
      " True Negative : 1929\n",
      "\n",
      "ADA Boost \n",
      "\n",
      "Train Data Evaluation Score\n",
      "AUCROC: 0.9123487589672521\n",
      "--------------\n",
      "Test Data Evaluation Scores\n",
      "AUCROC: 0.8370686091265336\n",
      "Sensitivity: 0.7318840579710145\n",
      "Precision: 0.15279878971255673\n",
      "F1_score: 0.2528160200250313\n",
      "--------------\n",
      "Outcome values :\n",
      " True Positive : 101 \n",
      " False Negative: 37 \n",
      " False Positive: 560 \n",
      " True Negative : 1929\n",
      "\n",
      "Gradient Boost \n",
      "\n",
      "Train Data Evaluation Score\n",
      "AUCROC: 0.9123487589672521\n",
      "--------------\n",
      "Test Data Evaluation Scores\n",
      "AUCROC: 0.8358982421204022\n",
      "Sensitivity: 0.7318840579710145\n",
      "Precision: 0.15279878971255673\n",
      "F1_score: 0.2528160200250313\n",
      "--------------\n",
      "Outcome values :\n",
      " True Positive : 101 \n",
      " False Negative: 37 \n",
      " False Positive: 560 \n",
      " True Negative : 1929\n",
      "\n",
      " Neural Network \n",
      "\n",
      "Train Data Evaluation Score\n",
      "AUCROC: 0.8753540830764256\n",
      "--------------\n",
      "Test Data Evaluation Scores\n",
      "AUCROC: 0.8381137876220588\n",
      "Sensitivity: 0.8115942028985508\n",
      "Precision: 0.1322314049586777\n",
      "F1_score: 0.22741116751269036\n",
      "--------------\n",
      "Outcome values :\n",
      " True Positive : 112 \n",
      " False Negative: 26 \n",
      " False Positive: 735 \n",
      " True Negative : 1754\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression \\n')\n",
    "metrics(lr,X_train_sm,y_train_sm,X_holdout,y_holdout)\n",
    "print('\\nRandom Forest\\n')\n",
    "metrics(rf,X_train_sm,y_train_sm,X_holdout,y_holdout)\n",
    "print('\\nADA Boost \\n')\n",
    "metrics(ada,X_train_sm,y_train_sm,X_holdout,y_holdout)\n",
    "print('\\nGradient Boost \\n')\n",
    "metrics(gb,X_train_sm,y_train_sm,X_holdout,y_holdout)\n",
    "print('\\n Neural Network \\n')\n",
    "metrics(nn,X_train_sm,y_train_sm,X_holdout,y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4e84f",
   "metadata": {
    "id": "69b4e84f"
   },
   "source": [
    "### Selected Model:\n",
    "\n",
    "To select the best model, we consider the following factors:\n",
    "\n",
    "##### 1) High Recall/Specificity:\n",
    "\n",
    "The ideal model will have a high recall. We are interested in the positive class (WNV present), recall captures the proportion of positive classes predicted correctly by the model.\n",
    "\n",
    "##### 2) Low ROCAUC difference between training and validation data: \n",
    "\n",
    "An ideal model will control for overfitting, if the ROC AUC score between the training and validation data is small, it implies that the model is not overfitted to the train data. ROC AUC score was used as the evaluation metrics of choice because we are training the data on data that is transformed by SMOTE. Accuracy, recall and other metrics that are prediction dependent may not be applicable as the validation data remains imbalanced.\n",
    "\n",
    "The following is a table of our models and the evaluation metrics generated:\n",
    "\n",
    "|  | Logistic Regression | Random Forest | ADA Boost | Gradient Boost | Neural Network |\n",
    "|---|---|---|---|---|---|\n",
    "| **Train ROC AUC** | 81.90% | 91.20% | 91.23% | 91.23% |87.54%|\n",
    "| **ROC AUC** | 80.86% | 85.12% | 79.55% | 80.80% |86.13%|\n",
    "| **Recall** | 79.71% | 87.68% | **97.10%** | 97.10% |88.41%|\n",
    "| **Precision** | 12.29% | 13.12% | 9.65% | 9.96% |13.77%|\n",
    "| **F1 score** | 21.30% | 22.83% | 17.55% | 18.06% |23.83%|\n",
    "\n",
    "Our best model is the ADA Boost model. It achieves a recall of 97.10%, successfully predicting most of the WNV cases. A drawback of the model is that the precision is 9.65%. This is expected as we are using mainly weather data to predict whether a trap has west nile virus. This is problematic as not all traps will have west nile virus on a given day, but the same weather data will be used to predict all the traps. Hence, with our approach, we expect to see a low precision score. Suggestions on how to improve the model precision are stated in the [Future Work](#future) section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae67495",
   "metadata": {
    "id": "0ae67495"
   },
   "source": [
    "<a id='kaggle'></a>\n",
    "## Kaggle Evaluation\n",
    "\n",
    "In this section, we create submission files to upload on [Kaggle](https://www.kaggle.com/c/predict-west-nile-virus/overview). We re-train the models on the entire dataset to generate submission file of real-valued probability that WNV is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7831cf2e",
   "metadata": {
    "id": "7831cf2e",
    "outputId": "2c93d23c-2219-449e-abf2-bf21b44d16d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Standard Scaler\n",
    "fix_cols = [x for x in X.columns if x.startswith('culex') or x.startswith('weathertype') or x.startswith('wnvpresent')]\n",
    "cols = [x for x in X.columns if x not in fix_cols]\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_sc = X\n",
    "for i in cols:\n",
    "    X_sc.loc[:,i] = ss.fit_transform(X[[i]])\n",
    "    X_test.loc[:,i] = ss.transform(X_test[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d83defcb",
   "metadata": {
    "id": "d83defcb"
   },
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "sm = SMOTE(random_state = 25)\n",
    "\n",
    "X_sm, y_sm = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22983d91",
   "metadata": {
    "id": "22983d91",
    "outputId": "c085ce25-5bcd-4e9c-967a-f0e31b91f4fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.61801138\n",
      "Validation score: 0.726481\n",
      "Iteration 2, loss = 0.54097648\n",
      "Validation score: 0.765651\n",
      "Iteration 3, loss = 0.50931410\n",
      "Validation score: 0.778038\n",
      "Iteration 4, loss = 0.49022102\n",
      "Validation score: 0.774690\n",
      "Iteration 5, loss = 0.47676643\n",
      "Validation score: 0.783395\n",
      "Iteration 6, loss = 0.46692781\n",
      "Validation score: 0.788416\n",
      "Iteration 7, loss = 0.46024542\n",
      "Validation score: 0.790090\n",
      "Iteration 8, loss = 0.45393043\n",
      "Validation score: 0.796117\n",
      "Iteration 9, loss = 0.44911583\n",
      "Validation score: 0.793773\n",
      "Iteration 10, loss = 0.44520466\n",
      "Validation score: 0.791430\n",
      "Iteration 11, loss = 0.44188939\n",
      "Validation score: 0.801808\n",
      "Iteration 12, loss = 0.43988144\n",
      "Validation score: 0.794777\n",
      "Iteration 13, loss = 0.43718172\n",
      "Validation score: 0.802143\n",
      "Iteration 14, loss = 0.43485799\n",
      "Validation score: 0.802812\n",
      "Iteration 15, loss = 0.43298526\n",
      "Validation score: 0.805490\n",
      "Iteration 16, loss = 0.43108279\n",
      "Validation score: 0.807834\n",
      "Iteration 17, loss = 0.42943538\n",
      "Validation score: 0.806830\n",
      "Iteration 18, loss = 0.42850052\n",
      "Validation score: 0.805156\n",
      "Iteration 19, loss = 0.42668873\n",
      "Validation score: 0.812856\n",
      "Iteration 20, loss = 0.42526557\n",
      "Validation score: 0.806830\n",
      "Iteration 21, loss = 0.42468376\n",
      "Validation score: 0.810847\n",
      "Iteration 22, loss = 0.42380758\n",
      "Validation score: 0.804821\n",
      "Iteration 23, loss = 0.42237480\n",
      "Validation score: 0.813525\n",
      "Iteration 24, loss = 0.42209202\n",
      "Validation score: 0.809173\n",
      "Iteration 25, loss = 0.42017209\n",
      "Validation score: 0.816204\n",
      "Iteration 26, loss = 0.42010453\n",
      "Validation score: 0.809173\n",
      "Iteration 27, loss = 0.41898738\n",
      "Validation score: 0.810512\n",
      "Iteration 28, loss = 0.41831511\n",
      "Validation score: 0.810512\n",
      "Iteration 29, loss = 0.41728904\n",
      "Validation score: 0.813190\n",
      "Iteration 30, loss = 0.41808078\n",
      "Validation score: 0.816204\n",
      "Iteration 31, loss = 0.41731582\n",
      "Validation score: 0.811517\n",
      "Iteration 32, loss = 0.41674189\n",
      "Validation score: 0.813525\n",
      "Iteration 33, loss = 0.41553389\n",
      "Validation score: 0.813860\n",
      "Iteration 34, loss = 0.41536580\n",
      "Validation score: 0.815534\n",
      "Iteration 35, loss = 0.41297708\n",
      "Validation score: 0.813860\n",
      "Iteration 36, loss = 0.41370928\n",
      "Validation score: 0.814195\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(early_stopping=True, learning_rate='adaptive', max_iter=2000,\n",
       "              random_state=25, validation_fraction=0.15, verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selected model\n",
    "model1 = lr\n",
    "model2 = rf\n",
    "model3 = ada\n",
    "model4 = gb\n",
    "model5 = nn\n",
    "#Retrain model on full training set\n",
    "model1.fit(X_sm,y_sm)\n",
    "model2.fit(X_sm,y_sm)\n",
    "model3.fit(X_sm,y_sm)\n",
    "model4.fit(X_sm,y_sm)\n",
    "model5.fit(X_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab219da4",
   "metadata": {
    "id": "ab219da4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "models = [model1, model2, model3, model4, model5]\n",
    "count = 0\n",
    "for model in models:\n",
    "    submission = pd.DataFrame()\n",
    "    submission['Id'] = test_df['id']\n",
    "    submission['WnvPresent'] = model.predict_proba(X_test)[:,1]\n",
    "    count+=1\n",
    "    submission.to_csv(f'../../datasets/submission{str(count)}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdd632",
   "metadata": {
    "id": "f3fdd632"
   },
   "source": [
    "### Kaggle score:\n",
    "\n",
    "Kaggle returns the AUCROC score of the test dataset:\n",
    "\n",
    "Logistic Regression: 0.67515\n",
    "\n",
    "Random Forest: 0.6628\n",
    "\n",
    "Ada Boost: 0.66842\n",
    "\n",
    "Gradient Boost: 0.65783\n",
    "\n",
    "Neural Network: 0.62480\n",
    "\n",
    "We observe a slight decrease in the ROCAUC scores in our models. This hints that our models are showing signs of overfitting on 2007, 2009, 2011, 2013 data (train dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a81e63",
   "metadata": {
    "id": "79a81e63"
   },
   "source": [
    "<a id='conclude'></a>\n",
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f051678",
   "metadata": {
    "id": "3f051678"
   },
   "source": [
    "In conclusion, the selected model performs sufficiently well as a screening tool, with a recall of 97.10% and validation AUC-ROC score of 66.84% (kaggle). However there is definitely room for improvement and fine-tuning. \n",
    "\n",
    "The strongest features from the modeling process revealed that the occurence of WNV is correlated to weather data which predict rainfall, which creates ideal conditions for mosquitos to  breed and amplify the spread of the WNV. Since the eggs take time to hatch, weather features which describe past weather data became powerful predictors. This leads us to recommend a two-step approach to mosquito control.\n",
    "\n",
    "Spraying strategy involves 2 types of pesticides:\n",
    "- Type 1: Targets the **larvae and pupae** and is applied directly onto containers/areas that may potentially accumulate stagnent water. This should be applied ahead of potential spikes in mosquito numbers.\n",
    "- Type 2: Targets the **adult mosquito**, and is applied via aerosol spray at local clusters.\n",
    "[Source: Central Mass Mosquito Control Project](https://www.cmmcp.org/pesticide-information/pages/products-we-use)\n",
    "\n",
    "Spraying should be conducted during the summer months (between June - September), when weather conditions begin to favour mosquito breeding.\n",
    "\n",
    "Spraying should cover a radius of at least 3 km as the main species Culex Pipiens has been studied to have a mean flight distance of 1.5km and maximum flight distance of 3km.\n",
    "[Source: Dispersal of Adult Culex Mosquitoes in an Urban West Nile Virus Hotspot](https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0002768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f6b6a",
   "metadata": {
    "id": "2f2f6b6a"
   },
   "source": [
    "<a id='future'></a>\n",
    "### Future Work\n",
    "The following suggestions may further improve on the model's precision but require additional data to proceed.\n",
    "\n",
    "#### Include more localized environmental data besides weather\n",
    "A major limitation of our model is that our inputs are based on average city-wide weather conditions. This does not allow us to predict localized mosquito clusters, making it difficult to narrow down our predictions to specific areas of interest. To overcome this limitation, we can include additional data which describe localized environmental features that could depict the extent of urbanization, or footfall/population density of the particular area etc.\n",
    "\n",
    "#### Include more spray data\n",
    "More spray data can be included to better evaluate the effectiveness of the current spraying strategy, and conduct a cost/benefit analysis for spraying to gain further insights on how to improve on the current programme.\n",
    "\n",
    "#### Ensemble methods\n",
    "We can combine the predictions from different models to incorporate the strengths of multiple models into our final model. For instance, AdaBoost gave the best sensitivity while Logistic Regression performed best in terms of minimal overfitting. By combining the predictions from these two models, we can create an encemble method which combines the benefits of using each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5826f97",
   "metadata": {
    "id": "e5826f97"
   },
   "outputs": [],
   "source": [
    "#Ensemble method using 40% log-reg and 60% ada boost\n",
    "ensemble_predictions =  0.4*(model1.predict_proba(X_test)[:,1]) + 0.6*(model3.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b7d6306",
   "metadata": {
    "id": "1b7d6306",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_ensemble = pd.DataFrame()\n",
    "submission_ensemble['Id'] = test_df['id']\n",
    "submission_ensemble['WnvPresent'] = ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "098b58ab",
   "metadata": {
    "id": "098b58ab"
   },
   "outputs": [],
   "source": [
    "submission_ensemble.to_csv('../../datasets/submission_ensemble.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333d08d",
   "metadata": {
    "id": "e333d08d"
   },
   "source": [
    "The ensemble model scored an ROCAUC score of 0.70643 on the unseen Kaggle data. There is room for improvement for our models if more combination of ensemble methods are used."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ac6ec98e",
    "7dfe88b6",
    "718507d4",
    "debb2ddb",
    "ffc04e93",
    "39356230",
    "ab2ed202",
    "2f2f6b6a",
    "e333d08d"
   ],
   "name": "Project 4 - Modelling Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
